# AI-generatedEmail-Spam-Detection-
Hacking attempts have shown a significant rise due to development of Artificially
Intelligent tools like ChatGPT, WormGPT, FraudGPT etc. Financially motivated hackers
have used such tools to target businesses and specifically retool existing malicious
programmes to infect hardware, software, application often leading to tempering,
exposing, disabling or distorting information through unauthorized access to computers
for either monetary, political or personal gains. Attackers can manipulate the datasets to
train AI, making subtle changes to carefully designed parameters to ignore increasing
suspicion while slowly steering AI in the desired direction. Artificial intelligence can
learn to detect behavior patterns, figuring out how to convince people that a video, phone
call, or email is legitimate. It then can persuade them to compromise networks and hand
over sensitive data. Malicious email classification is a traditional problem in Nature
Language Process (NLP) and with rise of AI generated LLM models there is a significant
rise posing a future threat to online Text related attacks like phishing, online harassments,
BEC, etc. Thus, increasing the need to make a robust defense system to defend ourselves
from such attacks.

# Approach :
Our project is designed to build a text classification model that can classify input text as either
"malicious" or "non-malicious." It uses a dataset consisting of two categories of text: "good text" and
"bad text," with "good text" representing non-malicious content and "bad text" representing
potentially malicious or harmful content. The model is trained to distinguish between these two
categories using na√Øve-bayes algorithm
